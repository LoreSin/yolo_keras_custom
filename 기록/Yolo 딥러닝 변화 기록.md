# 딥러닝 목표

1. 필수 검출대상
    - 차량 (car)
    - 사람 (person)
    - 얼굴(조원중 1명) : 민식으로 결정 (minsick)
    - 표지판 (traffic sign)
    - 기타 등등.
        - tree, pillar (보행시 정적인 대상)
        - motorcycle, bicycle

## 사용한 라이브러리

- python 3.7.3
- keras 2.3.1
- tensorflow 1.14.0
- flask 2.2.6


## Yolo 딥러닝 변화 기록 (10.21)

1. 트레이닝 셋업 (Google Cloud Platform)
    - aise tensorflow with cuda 환경 사용.
    - 어느정도 충분한 패키지들 모두 설치
    - GPU 는 V100 이든 P100 이든 충분히 빠르다.
    - 단, OS 차이로 인해서, 데이터셋의 xml to traindata 변환 코드를 한번 실행 시켜야 함
    - 미 설치된 일부 패키지 (pillow, matplotlib) 는 수동설치
    - 첫 작업 상 오래동안 걸어두는 장기트레이닝보다, 수정하며 트레이닝 하기 때문에, 빠른것이 좋을수 있을거라고 생각.
        - 사전훈련셋을 사용하면, 훈련시간이 크게 단축됨. (어느정도 사물의 피처를 잘 잡는 훈련이 된 셋이므로)
        - 사전훈련이 아닌,  아무것도 없는 훈련셋으로 작업시, 최소 수k iteration 필요

1. 라벨 3종 : 나무, 기둥, 민식 (tree, pillar, minsick)
    - 데이터 162개 - 50 epoch
        - custom_model_test1.h5 (중간모델명. 최종모델은 삭제 해버림)
        - 트레이닝 과정에서 약 40정도의 loss 수렴 : 중간적합모델
        - 그러나, 마지막에 val_loss 가 급격하게 올라간 상태로 마무리 : 최종모델
            * 중간적합모델 + 최종모델 을 가지고 테스트
            * 결과는 둘다 별로. 최종모델은 __오버플로우에러__를 발생 시킴
    - 데이터 191개 (데이터 약간 더 추가) - 50 epoch
        + custom_model_test2.h5
        + loss 35, val_loss 는 약 40~50정도
        + 에폭이 도중 중단됨. (개선 불가?) 검출이 안된다?


2. 라벨 1종 : 나무 (tree)
    - 사진 63. 대상은 약 200++
        + custom_model_test3.h5
        + loss 약 90, val_loss 90~100
        + 최종 및 최적모델의 loss 가 비슷하여, 최종모델 기준으로 테스트.
        + 왠지 모르게 또 0개 검출?

--- 
# yolo 학습 작업 관련 (10.22)
# 지금 디텍터 모듈에서 이상이 있는것으로 보임

- 원래모델(yolo.h3) 로 검출 할때는 이상이 없음.
- 직접 생성한 모델 (custom_model_X.h5) 로는 최초에 이상한 검출 이외에 데이터셋 내용으로 조차도 검출이 안됨.
- RGB 관련 문제인가 헀으나, YOLO 모델 자체에서 학습/검출시 이미지를 모두 RGB 로 변환시켜 학습하는 것을 확인. (이미지 색상 문제는 아님)

> 일단은 모델의 문제라 가정, 초기의 모델을 다시 생성키로 함.
 
1. 라벨 3종 : 나무, 기둥, 민식 (tree, pillar, minsick)
    - 데이터 191개
        + custom_model_test4.h5
        + 63 epoch 정지 (early stop), loss 33, val_loss 35
        + 거대한 tree 를 minsick 으로 0.46인식 하는 테스트가 발견됨. . .
        + 그외에 검출 거의 안됨

    - 데이터 103개
        + custom_model_test5.h5
        + 민식의 데이터중 일부를 제거함. (정면 얼굴 위주로 남김)
        + 79 epoch 정지 (early stop), loss 33, val_loss 35
        + minsick 의 뒤통수만 인식하는 경우. . . 
        + IOU, SCORE 를 낮춰보았으나(0.1, 0.25), 일부 다른 검출을 더 많이 할뿐, tree 나 pillar 를 검출하지는 못함.
    

- 생성된 모델 자체의 문제가 확실시 됨. 즉, 데이터셋의 라벨이 일관적이지 않은 문제
- 라벨링을 다시 하거나, 더 많이 해야 할 것으로 보임.
- 나무나 기둥은 검출이 이뤄지지 않음.
- 데이터셋을 더 확보.
- 이후로 얼굴의 데이터는 전후좌우 모두가 아닌, 정면위주로 선별된 것 사용. 

---

## 라벨 데이터 늘리기 (10.22~23)

1. 라벨 4종 : 나무, 기둥, 민식, 차 (tree, pillar, minsick, car)
    - 데이터종류에 차를 추가하고, 데이터셋을 늘림.
    - 데이터 174개
        + custom_model_test6.h5
        + 아무런 검출이 안됨. . . 


2. 라벨 5종 : 나무, 기둥, 민식, 차, 사람 (tree, pillar, minsick, car, person)
    - 사람의 데이터는 jaywalk (무단횡단) 사진의 데이터를 추가 
    - 데이터 243개
        + custom_model_test7.h5
        + loss 및 val_loss 는 약 70 정도 
        + 일부의 tree 를 잡아냄. 특히 밀집된 지역은 자주 찾아냄.
            * 하지만, 최대 0.2 score 정도 뿐.
            * 데이터중 나무가 빼곡히 겹쳐 있던 것을 라벨링 하여 그런것으로 보여짐.
        + 오검출이지만, 일부 car 도 나옴
            * 오검출이 대부분
            * 차량을 보긴 하는 경우도 있지만, score 가 낮음. (0.05도 안나옴)
    - 결론은 라벨링과 데이터
        + 일부 다른 커스텀 욜로모델의 자료를 찾아본 결과
            * 학습시 배치는 5천~1만 단위로 수행함. (상대적으로 욜로모델이 학습이 빨라서 그런듯)
            * 데이터는 최저 수백 (200~300) 일반적으로는 천단위, 과하게는 1만단위 까지
            * 데이터의 품질에 따라서, 최저 300~500 으로도 가능한 학습은 1만까지 돌리기도 하고, 어떤 경우는 1천 개의 데이터를 쓰고 5천번 가량을 돌리기도 한다.
            * 결론은, __데이터 품질__ + __학습량__
        + 먼저 학습량을 5배 늘려서 (50 epoch => 250 epoch) 검출의 차이여부 시도
            * custom_model_test8.h5
            * loss 40 및 val_loss 는 50 
            * 모든 라벨링에 대해서, 출력답이 나옴. score 가 90 이상으로 검출되는 대상들이 나오기 시작함.
            * 종종 오답은 있으나, 전혀 안나오는 답이 생기는 경우는 없음.
            * 다른 사진 (트레이닝에 쓰이지 않은 사진) 을 사용할때도 어느정도 검출이 되기는 함.


3. 욜로80 + 나무 + 기둥 + 민식
    - 욜로 80 가지는 충분한 기존데이터가 많다. 그러니, 새로운 데이터를 추가하여 종류를 늘릴수 있지 않을까
    - 총 83종
    - 우리가 검출하고자 하는 트리 + 기둥 + 민식이 기존의 검출대상에 추가되는지, 혹은 혼란을 주어 기존 데이터 조차도 검출하기 어려워지는지 시험해보기
    - 추가 작업목록
        + 기존 욜로 classes 를 기준으로, train.txt 파일을 생성하기 (라벨붙이기)
        + train 코드에서 기존의 모델을 사용한다는 코드부분을 변경해야함. 새로 코드를 만들어서 작업해야 혼동이 없을 것 같음. 
        + xml_make-addYolo80.py, train_code_custom-addYolo80.py 으로 변경
        + coco_clesses.txt 에 3개의 아이템이 추가되었음.
    - 학습 시작. 
        + 트레인 횟수는 250epoch + 50 epoch (파인튜닝)
        + loss 39.1, val_loss 46.7
        + yolo83_test1.h5
        + 학습시켯던 범주(나무, 기둥, 민식) 들이 좀 더 올라갔음.
        + 그러나, 기존 학습되었을 80개의 대상중, car 가 인식률은 올라갔으나, 원래 yolo80 이 갖고 있던 인식을 해쳐버리는 상황이 발생.
            * 기존에는 트럭, 버스등도 모두 car 로 라벨링 한 데이터들로 인해서, 기존의 트레이닝된 데이터들이 무효화된 것으로 보임.
            * 새로이 학습되는 데이터에 따라서 데이터가 결국 편향되는 것으로 보임. (아무래도 높은 epoch 이 기존의 데이터를 지워버릴정도의 영향을 준 것도 의심 스러움)
            * 에폭을 낮춰서 한번 시도.
    -   2차 학습
        + 트레인 횟수는 50epoch + 50 epoch (파인튜닝)
        + loss , val_loss 
        + yolo83_test2.h5
        + 자동차, 나무등 잘 잡음.
        + 그러나 기존데이터들 (yolo80 에서 검출 가능하였던 것들) 은 죄다 사라짐. 새로 학습한 것들만 검출 가능.
        + 기존 욜로80 을 써서 새로운 학습을 하는 경우, 더 빠른 학습을 촉진하는 방법으로 보임. 기존의 검출대상을 포함하는 것이 아니라, 기존의 특징을 추출하는 피처를 활용하여, 사용자의 데이터셋을 반영, 그 결과값을 가져오는 것.
        + 욜로80은 많은 데이터셋을 훈련시켰으므로, 데이터셋이 충분히 좋다면 잘 잡게 되는 것으로 보임.
            * car 를 사용자 데이터로 넣을때, car-truck-bus 등에 해당하는 데이터셋을 넣었을때, 새로이 훈련시킨 데이터셋에 비해서 버스등을 매우 잘 인식하는 패턴을 보임.
            * 아무래도 기존 웨이트셋에서는 각 세부대상을 분류할 정도로 많은 분류가 가능했던 것이, 새로운 훈련시에는 유사한 대상들을 묶고자 할때, 훨씬 잘 수렴하는 것으로 추정됨.
            * 같은 이유로, 훨씬 더 세분류 (ex 차종을 맞춘다거나) 를 한다면, 욜로80 등의 범용세트보다, 해당 사진을 이용한 데이터셋으로 모델을 구축하는것이 적절하다고 보임. 

4. 데이터 추가 및 재 라벨링
    - 기존데이터 재라벨링
        + 기존에 분리하지 않았던 bus, truck 을 분리
        + 일부 tree 데이터를 보정함. (이상하게 잡았거나 애매한것 빼버림)
        + 신호등 및 교통표지판 추가.
    - traffic signs, traffic light 등 새로운 데이터셋 추가.
    - 총 9종의 라벨 306 데이터
        - custom_model_test9.h5
        - loss : 37, val_loss : 60
        - 어느정도 잘 잡히긴 함.
        - 다만 라벨에 있었던 트럭 & 버스는 제대로 못잡는 현상 발생 (데이터가 적어서 생긴 것으로 보임.)
        - 그리고 촘촘하게 잡았던 Tree 를 덜 촘촘하게 잡은 뒤로, 나무들이 걸리는 비중이 크게 줄어듬. 일정정도는 더티하더라도 잡는게 좋은 경우가 많은듯. (혹은 검출하고 싶은 수준의 크기까지는 잡아야 한다고 보임.)
        - 사실상 최종본으로 써야 할 것으로 생각중.
            + 자동차, 신호등 까지는 잘 잡힘. 표지판은 종종 못잡음.


## 번외 - 차량의 경우 거리측정? (10.24)
- 모델은 욜로검출모델 사용.
    + 일반화나 객체 검출이 잘 되어서 사용
    + 잘려진 차량의 사진이 아니라면, 충분히 bbox 의 크기가 나오는 편.

- 대체로 대상물의 크기를 일정한 경우가 많다.
    + 차량은 대략 1.5~1.8 m (모빌아이 시스템에서는 1.6m 로 가정)
    + 차량의 세로축을 1.6m 로 가정하고, 카메라의 시야각을 기준으로, 상하좌우 60' 가정, 픽셀간 각도를 계산하여, 픽셀크기를 기준으로 크기를 가정.
    + y축 픽셀거리는 높이를 이용해 거리를 측정.
    + x 축 픽셀거리는 대상의 신뢰성 (대략 x 와 y 가 비슷하면 후방, x가 크다면 측면으로 가정.)
    + 하단에 가까이 감지된 경우, 지근거리로 가정.
    + 계산식을 다음과 같이 하여, 근사적 값들로 계산
        * 기본적인 원리는 화상의 검출대상의 픽셀높이를 가지고 계산. (픽셀높이)
        * 차량높이 = 승용차 기준으로 1.6 가정
        * 카메라의 시야각 (Angle Of View, Field Of View) = 카메라 스펙로 가정. (45~80 정도? )
            - [카메라 시야각에 대한 정보](https://ko.wikipedia.org/wiki/%ED%99%94%EA%B0%81_(%EC%82%AC%EC%A7%84%EC%88%A0))
        * 차량높이를 가지고 거리를 구하기 위해, 삼각함수로 계산.
            - 차량높이 / tan-1(θ)
            - 실제 X,Y 데이터를 가지고 계산오차를 확인할수 없기에 대략적인 감각에 의존.
            - θ = 2 * FOV * detect_height / image_height
        * 거리 = height_rate / tan(radians(θ))
    - 승용차 기준으로 충분히 괜찮은 수준의 검출을 하는것으로 보임.

- 위 방식의 문제점으로 보이는것.
    + 대상의 bbox 가 정확하지 않으면 (적어도 타이어하단 - 차량 상단부까지)정밀도가 떨어진다. bbox.height 에 크게 의존하기 때문
        * 학습 데이터 잘 모아야함.
    + 별도의 센서로 교차검증이 되지 않음. 즉, 실제 데이터와 차이를 알기 어렵다.
        * 실시간 처리시, 라이다 또는 스테레오카메라등을 이용한 교정이 필수.
        * 같은 카메라기종을 이용시 다양한 주행 데이터 수집 가능.
    + 실제 차량들의 높이를 반영하지 못했다.
        * 다양한 차종의 데이터셋 (높이, 폭 등) 을 구축하여, 차량의 사진으로 차종을 검출, 해당차량의 높이를 DB 에서 반영한다면, 정밀도를 높일수 있을 것.

- 가능성 있는 방법들
    + 검출된 객체의 일반높이 (ex 버스 3m, 승합차 2.2m 등) 을 도입하면 다양한 거리측정 가능.
    + 사람은 자세에 따라 크기가 달라지므로, 포즈검출이 가능한 방법을 구현하여 측정하는 것이 적정.
    + 차종에 따른 스펙DB 가 존재한다면, 차종검출기를 구현하여 상세한 거리측정오차 줄일수 있을 것.
